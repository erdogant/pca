<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Quickstart &mdash; pca pca documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Notebook" href="notebook.html" />
    <link rel="prev" title="Load dataset" href="Plots.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            pca
          </a>
              <div class="version">
                2.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Abstract.html">Background</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html#uninstalling">Uninstalling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Methods</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Algorithm.html">Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="Algorithm.html#standardization">Standardization</a></li>
<li class="toctree-l1"><a class="reference internal" href="Algorithm.html#explained-variance">Explained Variance</a></li>
<li class="toctree-l1"><a class="reference internal" href="Algorithm.html#loadings">Loadings</a></li>
<li class="toctree-l1"><a class="reference internal" href="Algorithm.html#examination-of-the-loadings">Examination of the loadings</a></li>
<li class="toctree-l1"><a class="reference internal" href="Algorithm.html#best-performing-features">Best Performing Features</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Outlier detection</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Outlier%20detection.html">Hotelling T2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Outlier%20detection.html#spe-dmodx">SPE/Dmodx</a></li>
<li class="toctree-l1"><a class="reference internal" href="Outlier%20detection.html#selection-of-the-outliers">Selection of the Outliers</a></li>
<li class="toctree-l1"><a class="reference internal" href="Outlier%20detection.html#detect-new-unseen-outliers">Detect new unseen outliers</a></li>
<li class="toctree-l1"><a class="reference internal" href="Outlier%20detection.html#detection-of-outliers-without-pca">Detection of outliers without PCA</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Plots</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Plots.html">Load dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#scatter-plot">Scatter plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#biplot">Biplot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#biplot-only-arrows">Biplot (only arrows)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#explained-variance-plot">Explained variance plot</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#alpha-transparency">Alpha Transparency</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#markers">Markers</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#control-color-marker-size-per-sample">Control color/marker/size per sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#d-plots">3D plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="Plots.html#toggle-visible-status">Toggle visible status</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#compute-explained-variance">Compute explained variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pcs-that-cover-95-of-the-explained-variance">PCs that cover 95% of the explained variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scatter-plot">Scatter plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#biplot">Biplot</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#demonstration-of-feature-importance">Demonstration of feature importance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#explained-variance-plot">Explained variance plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">Biplot</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#analyzing-discrete-datasets">Analyzing Discrete datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="#map-unseen-datapoints-into-fitted-space">Map unseen datapoints into fitted space</a></li>
<li class="toctree-l1"><a class="reference internal" href="#normalizing-out-pcs">Normalizing out PCs</a></li>
<li class="toctree-l1"><a class="reference internal" href="#colors-in-plots">Colors in plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebook.html">Notebook</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html">Sponsor</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#blog">Blog</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#github">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#colab-notebook">Colab Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="Documentation.html#citing">Citing</a></li>
<li class="toctree-l1"><a class="reference internal" href="Additional_Information.html">Additional Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="Coding%20quality.html">Coding quality</a></li>
<li class="toctree-l1"><a class="reference internal" href="pca.pca.html">API References</a></li>
</ul>

    <a href= "genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pca</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Quickstart</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Examples.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this heading"></a></h1>
<p>A quick example how perform feature reduction using <code class="docutils literal notranslate"><span class="pre">pca</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load pca</span>
<span class="kn">from</span> <span class="nn">pca</span> <span class="kn">import</span> <span class="n">pca</span>

<span class="c1"># Load dataset</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">feature_names</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Initialize to reduce the data up to the nubmer of componentes that explains 95% of the variance.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

<span class="c1"># Reduce the data towards 3 PCs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Fit transform</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Data looks like this:</span>

<span class="c1"># X=array([[5.1, 3.5, 1.4, 0.2],</span>
<span class="c1">#        [4.9, 3. , 1.4, 0.2],</span>
<span class="c1">#        [4.7, 3.2, 1.3, 0.2],</span>
<span class="c1">#        [4.6, 3.1, 1.5, 0.2],</span>
<span class="c1">#        ...</span>
<span class="c1">#        [5. , 3.6, 1.4, 0.2],</span>
<span class="c1">#        [5.4, 3.9, 1.7, 0.4],</span>
<span class="c1">#        [4.6, 3.4, 1.4, 0.3],</span>
<span class="c1">#        [5. , 3.4, 1.5, 0.2],</span>
<span class="c1">#</span>
<span class="c1"># y = [0, 0, 0, 0,...,2, 2, 2, 2, 2]</span>
<span class="c1"># label = [&#39;sepal length (cm)&#39;,</span>
<span class="c1">#        &#39;sepal width (cm)&#39;,</span>
<span class="c1">#        &#39;petal length (cm)&#39;,</span>
<span class="c1">#        &#39;petal width (cm)&#39;]</span>
</pre></div>
</div>
<section id="compute-explained-variance">
<h2>Compute explained variance<a class="headerlink" href="#compute-explained-variance" title="Permalink to this heading"></a></h2>
<p>After the <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>, the cumulative expained variance is stored together with the explained variance per PC.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cumulative explained variance</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;explained_var&#39;</span><span class="p">])</span>
<span class="c1"># [0.92461872 0.97768521 0.99478782]</span>

<span class="c1"># Explained variance per PC</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;variance_ratio&#39;</span><span class="p">])</span>
<span class="p">[</span><span class="mf">0.92461872</span><span class="p">,</span> <span class="mf">0.05306648</span><span class="p">,</span> <span class="mf">0.01710261</span><span class="p">]</span>

<span class="c1"># Make plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/fig_plot.png"><img alt="_images/fig_plot.png" class="align-center" src="_images/fig_plot.png" style="width: 600px;" /></a>
</section>
<section id="pcs-that-cover-95-of-the-explained-variance">
<h2>PCs that cover 95% of the explained variance<a class="headerlink" href="#pcs-that-cover-95-of-the-explained-variance" title="Permalink to this heading"></a></h2>
<p>The number of PCs can be reduced by setting the <code class="docutils literal notranslate"><span class="pre">n_components</span></code> parameter. Note that the number of components can never be larger than the number of variables in your dataset. By setting <code class="docutils literal notranslate"><span class="pre">n_components</span></code> <strong>larger than 1</strong>, a feature reduction will be performed to exactly that number of components. By setting <code class="docutils literal notranslate"><span class="pre">n_components</span></code> <strong>smaller than 1</strong>, it describes the percentage of explained variance that needs to be covered at least. Or in other words, by setting <code class="docutils literal notranslate"><span class="pre">n_components=0.95</span></code>, the number of components are extracted that cover at least 95% of the explained variance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reduce the data towards 3 PCs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># The number of components are extracted that cover at least 95% of the explained variance.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="scatter-plot">
<h2>Scatter plot<a class="headerlink" href="#scatter-plot" title="Permalink to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2D plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">scatter</span><span class="p">()</span>

<span class="c1"># 3d Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">scatter3d</span><span class="p">()</span>
</pre></div>
</div>
<table class="docutils align-center" id="id2">
<caption><span class="caption-text">Color on alcohol</span><a class="headerlink" href="#id2" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figE1" src="_images/fig_scatter.png" /></p></td>
<td><p><img alt="figE2" src="_images/fig_scatter3d.png" /></p></td>
</tr>
</tbody>
</table>
</section>
<section id="biplot">
<h2>Biplot<a class="headerlink" href="#biplot" title="Permalink to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2D plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">PC</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># 3d Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">biplot3d</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">PC</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/fig_biplot.png"><img alt="_images/fig_biplot.png" class="align-center" src="_images/fig_biplot.png" style="width: 600px;" /></a>
</section>
</section>
<section id="demonstration-of-feature-importance">
<h1>Demonstration of feature importance<a class="headerlink" href="#demonstration-of-feature-importance" title="Permalink to this heading"></a></h1>
<p>This example is created to showcase the working of extracting features that are most important in a PCA reduction.
We will create random variables with increasingly more variance. The first feature (f1) will have most of the variance, followed by feature 2 (f2) etc.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the top features.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;topfeat&#39;</span><span class="p">])</span>

<span class="c1"># Import libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pca</span> <span class="kn">import</span> <span class="n">pca</span>

<span class="c1"># Lets create a dataset with features that have decreasing variance.</span>
<span class="c1"># We want to extract feature f1 as most important, followed by f2 etc</span>
<span class="n">f1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f3</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f4</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f5</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f6</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f7</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f8</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
<span class="n">f9</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>

<span class="c1"># Combine into dataframe</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">f1</span><span class="p">,</span><span class="n">f2</span><span class="p">,</span><span class="n">f3</span><span class="p">,</span><span class="n">f4</span><span class="p">,</span><span class="n">f5</span><span class="p">,</span><span class="n">f6</span><span class="p">,</span><span class="n">f7</span><span class="p">,</span><span class="n">f8</span><span class="p">,</span><span class="n">f9</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span><span class="s1">&#39;f2&#39;</span><span class="p">,</span><span class="s1">&#39;f3&#39;</span><span class="p">,</span><span class="s1">&#39;f4&#39;</span><span class="p">,</span><span class="s1">&#39;f5&#39;</span><span class="p">,</span><span class="s1">&#39;f6&#39;</span><span class="p">,</span><span class="s1">&#39;f7&#39;</span><span class="p">,</span><span class="s1">&#39;f8&#39;</span><span class="p">,</span><span class="s1">&#39;f9&#39;</span><span class="p">])</span>

<span class="c1"># Initialize and keep all PCs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">()</span>
<span class="c1"># Fit transform</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Print the top features.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;topfeat&#39;</span><span class="p">])</span>

<span class="c1"># The results show the expected results: f1 is the best, followed by f2 etc</span>
<span class="c1">#     PC      feature</span>
<span class="c1"># 0  PC1      f1</span>
<span class="c1"># 1  PC2      f2</span>
<span class="c1"># 2  PC3      f3</span>
<span class="c1"># 3  PC4      f4</span>
<span class="c1"># 4  PC5      f5</span>
<span class="c1"># 5  PC6      f6</span>
<span class="c1"># 6  PC7      f7</span>
<span class="c1"># 7  PC8      f8</span>
<span class="c1"># 8  PC9      f9</span>
</pre></div>
</div>
<section id="explained-variance-plot">
<h2>Explained variance plot<a class="headerlink" href="#explained-variance-plot" title="Permalink to this heading"></a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/explained_var_1.png"><img alt="_images/explained_var_1.png" class="align-center" src="_images/explained_var_1.png" style="width: 600px;" /></a>
</section>
<section id="id1">
<h2>Biplot<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h2>
<p>Make the biplot. It can be nicely seen that the first feature with most variance (f1), is almost horizontal in the plot, whereas the second most variance (f2) is almost vertical. This is expected because most of the variance is in f1, followed by f2 etc. Biplot in 3d. Here we see the nice addition of the expected f3 in the plot in the z-direction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2d plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># 3d plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">biplot3d</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center" id="id3">
<caption><span class="caption-text">Color on alcohol</span><a class="headerlink" href="#id3" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figA1" src="_images/biplot2d.png" /></p></td>
<td><p><img alt="figA2" src="_images/biplot3d.png" /></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="analyzing-discrete-datasets">
<h1>Analyzing Discrete datasets<a class="headerlink" href="#analyzing-discrete-datasets" title="Permalink to this heading"></a></h1>
<p>Analyzing datasets that have continuous and catagorical values can be challanging.
To demonstrate how to do this, I will use the Titanic dataset. We need to pip install df2onehot first.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install df2onehot
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pca</span>
<span class="c1"># Import example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">import_example</span><span class="p">()</span>

<span class="c1"># Transform data into one-hot</span>
<span class="kn">from</span> <span class="nn">df2onehot</span> <span class="kn">import</span> <span class="n">df2onehot</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">]</span>
<span class="k">del</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Name&#39;</span><span class="p">]</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">df2onehot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s1">&#39;onehot&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">y</span>


<span class="kn">from</span> <span class="nn">pca</span> <span class="kn">import</span> <span class="n">pca</span>

<span class="c1"># Initialize</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">onehot</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Run model 1</span>
<span class="n">model1</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># len(np.unique(model1.results[&#39;topfeat&#39;].iloc[:,1]))</span>
<span class="n">model1</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;topfeat&#39;</span><span class="p">]</span>
<span class="n">model1</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;outliers&#39;</span><span class="p">]</span>

<span class="n">model1</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">model1</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model1</span><span class="o">.</span><span class="n">biplot3d</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model1</span><span class="o">.</span><span class="n">scatter</span><span class="p">()</span>
<span class="n">model1</span><span class="o">.</span><span class="n">scatter3d</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">pca</span> <span class="kn">import</span> <span class="n">pca</span>
<span class="c1"># Initialize</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">onehot</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># Run model 2</span>
<span class="n">model2</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">model2</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">scatter</span><span class="p">()</span>
<span class="n">model2</span><span class="o">.</span><span class="n">biplot3d</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Set custom transparency levels</span>
<span class="n">model2</span><span class="o">.</span><span class="n">biplot3d</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">scatter3d</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Initialize</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Run model 2</span>
<span class="n">_</span><span class="o">=</span><span class="n">model3</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">model3</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">n_feat</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="map-unseen-datapoints-into-fitted-space">
<h1>Map unseen datapoints into fitted space<a class="headerlink" href="#map-unseen-datapoints-into-fitted-space" title="Permalink to this heading"></a></h1>
<p>After fitting variables into the new principal component space, we can map new unseen samples into this space too. However, there is also normalization step which can be tricky because you now need standardize the values of the unseen samples first based on the previously performed standardization. This step is also integrated in the <code class="docutils literal notranslate"><span class="pre">pca</span></code> library by simply setting the parameter <code class="docutils literal notranslate"><span class="pre">normalize=True</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load libraries</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pca</span> <span class="kn">import</span> <span class="n">pca</span>

<span class="c1"># Load dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_wine</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">col_labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">feature_names</span>

<span class="c1"># Initialize with normalization and take the number of components that covers at least 95% of the variance.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># Get some random samples across the classes</span>
<span class="n">idx</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">53</span><span class="p">,</span><span class="mi">54</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>
<span class="n">X_unseen</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">y_unseen</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Label original dataset to make sure the check which samples are overlapping</span>
<span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;unseen&#39;</span>

<span class="c1"># Fit transform</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">col_labels</span><span class="o">=</span><span class="n">col_labels</span><span class="p">,</span> <span class="n">row_labels</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Transform new &quot;unseen&quot; data. Note that these datapoints are not really unseen as they are readily fitted above.</span>
<span class="c1"># But for the sake of example, you can see that these samples will be transformed exactly on top of the orignial ones.</span>
<span class="n">PCnew</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_unseen</span><span class="p">)</span>

<span class="c1"># Plot PC space</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Map unseen samples in the existing space.&#39;</span><span class="p">)</span>
<span class="c1"># Plot the new &quot;unseen&quot; samples on top of the existing space</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">PCnew</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">PCnew</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/wine_mapping_samples.png"><img alt="_images/wine_mapping_samples.png" class="align-center" src="_images/wine_mapping_samples.png" style="width: 600px;" /></a>
</section>
<section id="normalizing-out-pcs">
<h1>Normalizing out PCs<a class="headerlink" href="#normalizing-out-pcs" title="Permalink to this heading"></a></h1>
<p>Normalize your data using the principal components. As an example, suppose there is (technical) variation in the fist component and you want that out. This function transforms the data using the components that you want, e.g., starting from the 2nd PC, up to the OC that contains at least 95% of the explained variance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="p">(</span><span class="mi">178</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span>

<span class="c1"># Normalize out 1st component and return data</span>
<span class="n">Xnorm</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pcexclude</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># The data remains the same samples and variables but the all variance that covered the 1st PC is removed.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Xnorm</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="p">(</span><span class="mi">178</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span>

<span class="c1"># In this case, PC1 is &quot;removed&quot; and the PC2 has become PC1 etc</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">col_labels</span><span class="o">=</span><span class="n">col_labels</span><span class="p">,</span> <span class="n">row_labels</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="colors-in-plots">
<h1>Colors in plots<a class="headerlink" href="#colors-in-plots" title="Permalink to this heading"></a></h1>
<p>The default colors that are used in the plots depend on how much information is provided at start.
There are many parameters to change the colors in the plots. Here I will demonstrate some of the possibilities.</p>
<p>First, we will load the data and import the libraries.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import iris dataset and other required libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">colourmap</span>

<span class="c1"># Import pca</span>
<span class="kn">from</span> <span class="nn">pca</span> <span class="kn">import</span> <span class="n">pca</span>

<span class="c1"># Class labels</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Initialize pca</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Dataset</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">load_iris</span><span class="p">()</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="c1"># Fit transform</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>Lets start with the default plot using hte classlabels (y), and change it using a custom cmap.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The default setting is to color on classlabels (y). These are provided as the index in the dataframe.</span>
<span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">()</span>

<span class="c1"># Use custom cmap for classlabels (as an example I explicitely provide three colors).</span>
<span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<table class="docutils align-center" id="id4">
<caption><span class="caption-text">Left: Default plot using the provided classlabels. Right: Color on custom cmap.</span><a class="headerlink" href="#id4" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figE3" src="_images/color_default.png" /></p></td>
<td><p><img alt="figE4" src="_images/color_cmap.png" /></p></td>
</tr>
</tbody>
</table>
<p>If you want to highlight some samples in the graph, you easily change the classlabels.
The colors are automatically created using the specified colormap. However, this can cause that
the points of interest can still be difficult to find. Therefore it is also possible to set the
input colors for each sample manually.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set custom classlabels. Coloring is based on the input colormap (cmap).</span>
<span class="n">y</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span><span class="o">=</span><span class="mi">4</span>
<span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Set2&#39;</span><span class="p">)</span>

<span class="c1"># Set custom classlabels and also use custom colors.</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">colourmap</span><span class="o">.</span><span class="n">fromlist</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Set2&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">c</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center" id="id5">
<caption><span class="caption-text">Left: Mark some points on y and use cmap. Right: Specify the colors manually.</span><a class="headerlink" href="#id5" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figE5" src="_images/color_cmap_y.png" /></p></td>
<td><p><img alt="figE6" src="_images/color_using_custom_colors.png" /></p></td>
</tr>
</tbody>
</table>
<p>The highlight the loadings, all scatterpoints can be removed by setting the cmap to None.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Remove scatterpoints by setting cmap=None</span>
<span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Gradient with white ending using the cmap setting.</span>
<span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="s1">&#39;#ffffff&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<table class="docutils align-center" id="id6">
<caption><span class="caption-text">Left: Remove scatterpoints from plot. Right: Gradient with the used cmap.</span><a class="headerlink" href="#id6" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figE7" src="_images/color_no_scatter.png" /></p></td>
<td><p><img alt="figE8" src="_images/color_gradient.png" /></p></td>
</tr>
</tbody>
</table>
<p>It is also possible to input a fig as parameter to the plot.
This will allow to make iterative changes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_friedman1</span>
<span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_friedman1</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Init</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pca</span><span class="p">()</span>
<span class="c1"># Fit</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Make plot with blue arrows and text</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">arrowdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span><span class="s1">&#39;normal&#39;</span><span class="p">},</span> <span class="n">color_arrow</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">HT2</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_feat</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Use the existing fig and create new edits such red arrows for the first three loadings. Also change the font sizes.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">biplot</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">arrowdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span><span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span><span class="s1">&#39;bold&#39;</span><span class="p">},</span> <span class="n">color_arrow</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">n_feat</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;updated fig.&#39;</span><span class="p">,</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-center" id="id7">
<caption><span class="caption-text">Fig as input to make iterative changes.</span><a class="headerlink" href="#id7" title="Permalink to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><img alt="figE9" src="_images/fig_iterative_changes.png" /></p></td>
</tr>
</tbody>
</table>
<hr>
<center>
        <script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>
        <!-- Show an image ad -->
        <!-- <div data-ea-publisher="erdogantgithubio" data-ea-type="image"></div> -->
        <div data-ea-publisher="erdogantgithubio" data-ea-type="image" data-ea-style="stickybox"></div>
</center>
<hr></section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Plots.html" class="btn btn-neutral float-left" title="Load dataset" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="notebook.html" class="btn btn-neutral float-right" title="Notebook" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Erdogan Taskesen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>